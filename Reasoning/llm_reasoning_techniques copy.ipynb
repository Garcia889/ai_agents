{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc39ad4d",
      "metadata": {
        "cell_marker": "\"\"\"",
        "id": "cc39ad4d"
      },
      "source": [
        "Advanced LLM Reasoning Techniques - Unit 2.4\n",
        "=======================================================================\n",
        "\n",
        "This unit focuses on implementing least-to-most decomposition techniques for solving\n",
        "complex problems. You'll develop systems that can break down problems into manageable\n",
        "sub-problems and solve them incrementally. In this exercise, you will also integrate and\n",
        "compare outputs from Deepseek R1 (Ollama) with ChatOpenAI, enhancing your understanding\n",
        "through model comparison and didactic analysis.\n",
        "\n",
        "### Key Concepts to Practice\n",
        "----------\n",
        "1. Problem Decomposition\n",
        "2. Dependency Management\n",
        "3. Incremental Solution Building\n",
        "4. Result Integration\n",
        "5. Solution Verification\n",
        "6. **Model Comparison:** Evaluate and compare the performance of Deepseek R1 (Ollama) against ChatOpenAI.\n",
        "\n",
        "Let's build sophisticated incremental problem-solving systems and learn how different LLMs handle decomposition!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9f4fda0",
      "metadata": {
        "cell_marker": "\"\"\"",
        "id": "f9f4fda0"
      },
      "source": [
        "## Step 0: Setup and Dependencies\n",
        "--------------------------------\n",
        "Ensure all required packages are installed. Uncomment the pip install commands below if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adae4b96",
      "metadata": {
        "id": "adae4b96"
      },
      "outputs": [],
      "source": [
        "!pip install numpy pandas matplotlib langchain openai python-dotenv --quiet\n",
        "!pip install typing-extensions pydantic pydantic_settings --quiet\n",
        "!pip install langchain-community langchain-openai --quiet\n",
        "!pip install -U langchain-ollama --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "846230f0",
      "metadata": {
        "cell_marker": "\"\"\"",
        "id": "846230f0"
      },
      "source": [
        "## Step 1: Initial Configuration\n",
        "--------------------------------\n",
        "Import necessary modules and classes for both ChatOpenAI and Deepseek R1 (Ollama)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8632cad",
      "metadata": {
        "id": "e8632cad"
      },
      "outputs": [],
      "source": [
        "from typing import Any, List\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_ollama import ChatOllama"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a431514",
      "metadata": {
        "cell_marker": "\"\"\"",
        "id": "9a431514"
      },
      "source": [
        "## Step 1.5: Configuration Management\n",
        "--------------------------------\n",
        "Configure API credentials and environment variables for both ChatOpenAI and Deepseek R1.\n",
        "Make sure to update the API keys in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e141556",
      "metadata": {
        "id": "9e141556"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pydantic_settings import BaseSettings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b61d584f",
      "metadata": {
        "cell_marker": "\"\"\"",
        "id": "b61d584f"
      },
      "source": [
        "Update the API keys below with your actual credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9470453c",
      "metadata": {
        "id": "9470453c"
      },
      "outputs": [],
      "source": [
        "# Configuration Values - Update these with your API keys\n",
        "OPENAI_API_KEY = \"your-openai-api-key-here\"   # Replace with your actual OpenAI API key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85458e5d",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 1,
        "id": "85458e5d"
      },
      "source": [
        "Define a Settings class to manage configuration for both LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55ae6df1",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "55ae6df1"
      },
      "outputs": [],
      "source": [
        "class Settings(BaseSettings):\n",
        "    \"\"\"Configuration management for API credentials.\n",
        "\n",
        "    This class manages API credentials for:\n",
        "    1. OpenAI (ChatOpenAI)\n",
        "    2. Ollama (Deepseek R1)\n",
        "\n",
        "    Attributes:\n",
        "        openai_api_key: OpenAI API key.\n",
        "        ollama_api_key: Ollama API key.\n",
        "        model_name: Identifier for the ChatOpenAI model.\n",
        "        deepseek_model_name: Identifier for Deepseek R1 from Ollama.\n",
        "        temperature: Model temperature setting.\n",
        "    \"\"\"\n",
        "    openai_api_key: str = OPENAI_API_KEY\n",
        "    model_name: str = \"gpt-4o-mini-2024-07-18\"\n",
        "    deepseek_model_name: str = \"Deepseek R1\"  # Adjust as needed for your Ollama configuration\n",
        "    temperature: float = 0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "231107de",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 1,
        "id": "231107de"
      },
      "source": [
        "Initialize the environment and create LLM instances for both models.\n",
        "This function sets environment variables and returns a dictionary containing both LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a6f7cd2",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "4a6f7cd2"
      },
      "outputs": [],
      "source": [
        "def setup_environment() -> dict:\n",
        "    \"\"\"Initialize environment and create LLM instances for model comparison.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with keys 'openai' and 'ollama' containing the respective model instances.\n",
        "    \"\"\"\n",
        "    # Load settings\n",
        "    settings = Settings()\n",
        "\n",
        "    # Set environment variables for API keys\n",
        "    os.environ[\"OPENAI_API_KEY\"] = settings.openai_api_key\n",
        "    os.environ[\"OLLAMA_API_KEY\"] = settings.ollama_api_key  # if required\n",
        "\n",
        "    # Initialize ChatOpenAI\n",
        "    openai_llm = ChatOpenAI(model_name=settings.model_name, temperature=settings.temperature)\n",
        "\n",
        "    # Initialize ChatOllama for Deepseek R1\n",
        "    ollama_llm = ChatOllama(model_name=settings.deepseek_model_name, temperature=settings.temperature)\n",
        "\n",
        "    return {\"openai\": openai_llm, \"ollama\": ollama_llm}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b68a83f",
      "metadata": {
        "cell_marker": "\"\"\"",
        "id": "1b68a83f"
      },
      "source": [
        "Attempt to initialize both LLM instances.\n",
        "If any errors occur, please verify that your API keys are correctly set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b91a68ed",
      "metadata": {
        "id": "b91a68ed"
      },
      "outputs": [],
      "source": [
        "# Initialize LLMs\n",
        "llm_instances = None\n",
        "try:\n",
        "    llm_instances = setup_environment()\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing LLMs: {e}\")\n",
        "    print(\"Please ensure your API keys are properly set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25ba9083",
      "metadata": {
        "cell_marker": "\"\"\"",
        "id": "25ba9083"
      },
      "source": [
        "## Usage Instructions:\n",
        "1. Run the pip install cell (if needed) to install dependencies.\n",
        "2. Update OPENAI_API_KEY and OLLAMA_API_KEY in the configuration cell.\n",
        "3. Execute the remaining cells to initialize the environment.\n",
        "4. Access your LLMs via the `llm_instances` dictionary:\n",
        "   - `llm_instances['openai']` for ChatOpenAI.\n",
        "   - `llm_instances['ollama']` for Deepseek R1 (Ollama).\n",
        "\n",
        "Keep your API keys secure and update settings as necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8016f19a",
      "metadata": {
        "cell_marker": "\"\"\"",
        "id": "8016f19a"
      },
      "source": [
        "## Problem 4: Incremental Problem-Solving System\n",
        "--------------------------------\n",
        "Design and implement a system that breaks down complex problems into manageable sub-problems\n",
        "and solves them incrementally. Your system should:\n",
        "\n",
        "1. **Problem Decomposition:**\n",
        "   - Break down the main problem into clear sub-problems.\n",
        "   - Identify logical dependencies among sub-problems.\n",
        "   - Ensure all aspects of the complex problem are covered.\n",
        "\n",
        "2. **Solution Strategy:**\n",
        "   - Solve sub-problems in dependency order.\n",
        "   - Reuse results where applicable.\n",
        "   - Track progress and handle error recovery.\n",
        "\n",
        "3. **Result Integration:**\n",
        "   - Assemble sub-problem solutions into a final, complete answer.\n",
        "   - Check for consistency and verify the overall solution.\n",
        "\n",
        "4. **Model Comparison:**\n",
        "   - Implement the system to run on both ChatOpenAI and Deepseek R1 (Ollama).\n",
        "   - Compare differences in decomposition, incremental solving, and final solution quality.\n",
        "   - Provide commentary on strengths and potential improvements for each model.\n",
        "\n",
        "### Didactic Enhancements:\n",
        "- Clearly document each decomposition step and dependency.\n",
        "- Explain the rationale behind the chosen sub-problems and their ordering.\n",
        "- Analyze the incremental integration process with detailed commentary."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc38744",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 1,
        "id": "dfc38744"
      },
      "source": [
        "### Base Classes:\n",
        "Define a model for sub-problem components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221a6947",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "221a6947"
      },
      "outputs": [],
      "source": [
        "class Subproblem(BaseModel):\n",
        "    \"\"\"Model for a single sub-problem component.\n",
        "\n",
        "    Attributes:\n",
        "        question: The sub-problem question to solve.\n",
        "        dependencies: List of indices representing dependencies on previous sub-problems.\n",
        "    \"\"\"\n",
        "    question: str = Field(..., description=\"The sub-problem to solve\")\n",
        "    dependencies: List[int] = Field(..., description=\"Indices of sub-problems this depends on\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4c9d8d1",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 1,
        "id": "f4c9d8d1"
      },
      "source": [
        "Implement the IncrementalSolver class that decomposes a problem into sub-problems,\n",
        "solves them in sequence, and integrates the results into a final solution.\n",
        "This class supports model comparison by allowing the user to choose the LLM to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f7c2ff9",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "2f7c2ff9"
      },
      "outputs": [],
      "source": [
        "class IncrementalSolver:\n",
        "    \"\"\"A system for solving problems through incremental decomposition.\n",
        "\n",
        "    This class breaks down complex problems into sub-problems, solves them based on their\n",
        "    dependencies, and integrates the results into a complete solution. It supports model\n",
        "    comparison by enabling the use of either ChatOpenAI or Deepseek R1 (Ollama).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm: Any, model_name: str = \"openai\"):\n",
        "        \"\"\"\n",
        "        Initialize the incremental solving system.\n",
        "\n",
        "        Args:\n",
        "            llm: An LLM instance or a dictionary of LLM instances.\n",
        "            model_name: Choose which model to use (\"openai\" or \"ollama\").\n",
        "        \"\"\"\n",
        "        if isinstance(llm, dict):\n",
        "            self.llm = llm.get(model_name)\n",
        "            if self.llm is None:\n",
        "                raise ValueError(f\"Model '{model_name}' not found in provided LLM dictionary.\")\n",
        "        else:\n",
        "            self.llm = llm\n",
        "        self.model_name = model_name\n",
        "        # Additional configuration for tracking progress and results can be added here\n",
        "\n",
        "    def decompose_problem(self, problem: str) -> List[Subproblem]:\n",
        "        \"\"\"\n",
        "        Break down the main problem into ordered sub-problems.\n",
        "\n",
        "        This method should:\n",
        "        1. Identify distinct components of the problem.\n",
        "        2. Establish dependencies between sub-problems.\n",
        "        3. Return a list of Subproblem objects in dependency order.\n",
        "\n",
        "        Args:\n",
        "            problem: The complex problem statement.\n",
        "\n",
        "        Returns:\n",
        "            List[Subproblem]: A list of sub-problems with dependencies.\n",
        "        \"\"\"\n",
        "        # TODO: Implement the decomposition logic using self.llm.\n",
        "        # Example pseudocode:\n",
        "        # prompt = f\"Decompose the following problem into sub-problems with dependencies:\\n{problem}\"\n",
        "        # response = self.llm.generate(prompt)\n",
        "        # Parse response into Subproblem objects.\n",
        "        pass\n",
        "\n",
        "    def solve_incrementally(self, problem: str) -> str:\n",
        "        \"\"\"\n",
        "        Solve the problem by addressing sub-problems in dependency order and integrating results.\n",
        "\n",
        "        This method should:\n",
        "        1. Decompose the problem into sub-problems.\n",
        "        2. Solve each sub-problem in order of dependency.\n",
        "        3. Assemble the intermediate results into a final solution.\n",
        "        4. Verify the consistency and correctness of the integrated result.\n",
        "\n",
        "        Args:\n",
        "            problem: The complex problem statement.\n",
        "\n",
        "        Returns:\n",
        "            str: The complete solution after incremental solving.\n",
        "        \"\"\"\n",
        "        # TODO: Implement incremental solving.\n",
        "        # Pseudocode:\n",
        "        # subproblems = self.decompose_problem(problem)\n",
        "        # results = {}\n",
        "        # for i, sub in enumerate(subproblems):\n",
        "        #     # Use results from dependencies if needed\n",
        "        #     prompt = f\"Solve the sub-problem: {sub.question}\\nUsing previous results: {results}\"\n",
        "        #     result = self.llm.generate(prompt)\n",
        "        #     results[i] = result\n",
        "        # final_solution = self.integrate_results(results)\n",
        "        # return final_solution\n",
        "        pass\n",
        "\n",
        "    # Optionally, implement helper methods like integrate_results() and verify_solution()."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b701ed1",
      "metadata": {
        "cell_marker": "\"\"\"",
        "id": "6b701ed1"
      },
      "source": [
        "### Example Test Problems:\n",
        "Below are sample problems to test your IncrementalSolver system.\n",
        "These examples illustrate scenarios where complex problems are decomposed,\n",
        "solved incrementally, and then reassembled into a final solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03cf7051",
      "metadata": {
        "id": "03cf7051"
      },
      "outputs": [],
      "source": [
        "test_problems = [\n",
        "    {\n",
        "        \"problem\": \"\"\"\n",
        "Calculate the total cost of a construction project with the following components:\n",
        "1. Materials cost $25,000 with 8% tax\n",
        "2. Labor is $45 per hour for 120 hours\n",
        "3. Equipment rental is $500 per day for 15 days\n",
        "4. Insurance is 5% of the subtotal (materials, labor, equipment)\n",
        "5. Add a 10% contingency to the final total\n",
        "\"\"\",\n",
        "        \"decomposition\": [\n",
        "            {\n",
        "                \"question\": \"Calculate materials cost including tax\",\n",
        "                \"dependencies\": [],\n",
        "                \"solution\": \"Materials with tax = $25,000 × 1.08 = $27,000\",\n",
        "            },\n",
        "            {\n",
        "                \"question\": \"Calculate total labor cost\",\n",
        "                \"dependencies\": [],\n",
        "                \"solution\": \"Labor cost = $45 × 120 = $5,400\",\n",
        "            },\n",
        "            {\n",
        "                \"question\": \"Calculate equipment rental cost\",\n",
        "                \"dependencies\": [],\n",
        "                \"solution\": \"Equipment = $500 × 15 = $7,500\",\n",
        "            },\n",
        "            {\n",
        "                \"question\": \"Calculate subtotal before insurance\",\n",
        "                \"dependencies\": [0, 1, 2],\n",
        "                \"solution\": \"Subtotal = $27,000 + $5,400 + $7,500 = $39,900\",\n",
        "            },\n",
        "            {\n",
        "                \"question\": \"Calculate insurance cost\",\n",
        "                \"dependencies\": [3],\n",
        "                \"solution\": \"Insurance = $39,900 × 0.05 = $1,995\",\n",
        "            },\n",
        "            {\n",
        "                \"question\": \"Calculate total with insurance\",\n",
        "                \"dependencies\": [3, 4],\n",
        "                \"solution\": \"Total with insurance = $39,900 + $1,995 = $41,895\",\n",
        "            },\n",
        "            {\n",
        "                \"question\": \"Add contingency to final total\",\n",
        "                \"dependencies\": [5],\n",
        "                \"solution\": \"Final total = $41,895 × 1.10 = $46,084.50\",\n",
        "            },\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"problem\": \"\"\"\n",
        "Write a function to process a list of transactions where each transaction includes a timestamp,\n",
        "amount, and category. The function should:\n",
        "1. Filter out invalid transactions (negative amounts)\n",
        "2. Group transactions by category\n",
        "3. Calculate total and average for each category\n",
        "4. Sort categories by total amount\n",
        "5. Return the top 3 categories with their statistics\n",
        "\"\"\",\n",
        "        \"decomposition\": [\n",
        "            {\n",
        "                \"question\": \"Define data structures for transaction processing\",\n",
        "                \"dependencies\": [],\n",
        "                \"solution\": \"Create a Transaction class and initialize result containers\",\n",
        "            },\n",
        "            {\n",
        "                \"question\": \"Implement transaction validation\",\n",
        "                \"dependencies\": [0],\n",
        "                \"solution\": \"Filter transactions to keep only those with positive amounts\",\n",
        "            },\n",
        "            {\n",
        "                \"question\": \"Group transactions by category\",\n",
        "                \"dependencies\": [1],\n",
        "                \"solution\": \"Use a dictionary to group transactions by category\",\n",
        "            },\n",
        "            {\n",
        "                \"question\": \"Calculate category statistics\",\n",
        "                \"dependencies\": [2],\n",
        "                \"solution\": \"Compute total and average for each category\",\n",
        "            },\n",
        "            {\n",
        "                \"question\": \"Sort categories by total amount\",\n",
        "                \"dependencies\": [3],\n",
        "                \"solution\": \"Sort the dictionary items by total amount in descending order\",\n",
        "            },\n",
        "            {\n",
        "                \"question\": \"Extract top 3 categories with statistics\",\n",
        "                \"dependencies\": [4],\n",
        "                \"solution\": \"Select the top 3 categories and format the results\",\n",
        "            },\n",
        "        ],\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b7eb51c",
      "metadata": {
        "cell_marker": "\"\"\"",
        "id": "9b7eb51c"
      },
      "source": [
        "### Implementation Requirements:\n",
        "\n",
        "1. **Code Quality:**\n",
        "   - Provide clear documentation and type hints.\n",
        "   - Include proper error handling and progress tracking.\n",
        "   - Ensure each decomposition and integration step is well-documented.\n",
        "\n",
        "2. **Decomposition Quality:**\n",
        "   - Logically break down the problem into coherent sub-problems.\n",
        "   - Clearly define dependencies between sub-problems.\n",
        "   - Ensure the decomposition covers all aspects of the complex problem.\n",
        "\n",
        "3. **Testing Approach:**\n",
        "   - Validate the decomposition and incremental solutions across multiple problem types.\n",
        "   - Verify that intermediate results are correctly integrated into the final solution.\n",
        "   - Consider edge cases and potential failure points.\n",
        "\n",
        "4. **Output Format:**\n",
        "   - Present sub-problem solutions, progress tracking, and the final integrated solution.\n",
        "   - Include detailed verification and commentary.\n",
        "   - Compare outputs from both ChatOpenAI and Deepseek R1 (Ollama) if available.\n",
        "\n",
        "5. **Model Comparison (Additional Requirement):**\n",
        "   - Implement the system to support both ChatOpenAI and Deepseek R1.\n",
        "   - Compare differences in decomposition logic, incremental solving, and result integration.\n",
        "   - Provide insights and didactic commentary on the strengths and weaknesses of each model.\n",
        "\n",
        "### Evaluation Criteria:\n",
        "\n",
        "Your solution will be evaluated based on:\n",
        "1. Logical decomposition and dependency management.\n",
        "2. Robustness and correctness of the incremental solution process.\n",
        "3. Quality of result integration and error handling.\n",
        "4. Clarity of documentation and didactic commentary.\n",
        "5. **Model Comparison Insight:** Depth of analysis comparing outputs from ChatOpenAI and Deepseek R1.\n",
        "\n",
        "### Tips for Success:\n",
        "\n",
        "1. Clearly define and document each sub-problem.\n",
        "2. Track and validate dependencies meticulously.\n",
        "3. Integrate results incrementally with thorough verification.\n",
        "4. Highlight differences between models and suggest improvements.\n",
        "5. Document assumptions and rationale at each step.\n",
        "\n",
        "### Common Pitfalls to Avoid:\n",
        "\n",
        "1. Circular dependencies or missing steps.\n",
        "2. Incomplete integration of sub-problem solutions.\n",
        "3. Poor error handling and lack of progress tracking.\n",
        "4. Insufficient documentation and didactic analysis.\n",
        "5. Overlooking differences between the LLMs used.\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "After completing this problem:\n",
        "1. Explore additional complex problem types.\n",
        "2. Enhance decomposition and integration strategies.\n",
        "3. Develop visualization tools for sub-problem dependencies.\n",
        "4. Implement caching or result reuse mechanisms.\n",
        "5. Expand your model comparison analysis."
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}